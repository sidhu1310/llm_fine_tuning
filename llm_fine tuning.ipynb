{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7707135,"sourceType":"datasetVersion","datasetId":4499795}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -q sentence_transformers==2.2.2\n! pip install -q -U langchain\n! pip install -q -U tiktoken\n! pip install -q -U pypdf\n! pip install -q -U faiss-gpu\n! pip install -q -U InstructorEmbedding \n! pip install -q -U bitsandbytes\n! pip install -q -U peft\n! pip install -q -U trl \n! pip install -q -U transformers \n! pip install -q -U accelerate\n! pip install -q -U bitsandbytes\n!pip install -q -U datasets==2.16.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-02-19T08:56:06.751666Z","iopub.execute_input":"2025-02-19T08:56:06.751974Z","iopub.status.idle":"2025-02-19T08:57:14.122076Z","shell.execute_reply.started":"2025-02-19T08:56:06.751952Z","shell.execute_reply":"2025-02-19T08:57:14.120940Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nimport os,torch\nfrom datasets import Dataset,load_dataset","metadata":{"execution":{"iopub.status.busy":"2025-02-19T08:57:14.123326Z","iopub.execute_input":"2025-02-19T08:57:14.123594Z","iopub.status.idle":"2025-02-19T08:57:36.833072Z","shell.execute_reply.started":"2025-02-19T08:57:14.123574Z","shell.execute_reply":"2025-02-19T08:57:36.832372Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T08:57:36.834372Z","iopub.execute_input":"2025-02-19T08:57:36.834686Z","iopub.status.idle":"2025-02-19T08:57:36.857718Z","shell.execute_reply.started":"2025-02-19T08:57:36.834657Z","shell.execute_reply":"2025-02-19T08:57:36.856864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(  \n    load_in_4bit= True,\n    bnb_4bit_quant_type= \"nf4\",\n    bnb_4bit_compute_dtype= torch.bfloat16,\n    bnb_4bit_use_double_quant= False\n)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T08:57:49.331985Z","iopub.execute_input":"2025-02-19T08:57:49.332392Z","iopub.status.idle":"2025-02-19T08:57:49.338433Z","shell.execute_reply.started":"2025-02-19T08:57:49.332357Z","shell.execute_reply":"2025-02-19T08:57:49.337328Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBERTv2-SS\")\nmodel = AutoModelForCausalLM.from_pretrained(\"ai4bharat/IndicBERTv2-SS\",quantization_config=bnb_config,\n    low_cpu_mem_usage = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T08:57:51.441187Z","iopub.execute_input":"2025-02-19T08:57:51.441626Z","iopub.status.idle":"2025-02-19T08:58:41.577850Z","shell.execute_reply.started":"2025-02-19T08:57:51.441590Z","shell.execute_reply":"2025-02-19T08:58:41.577170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBERTv2-SS\", trust_remote_code=True)\ntokenizer.padding_side = 'right'\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_eos_token = True\ntokenizer.add_eos_token","metadata":{"execution":{"iopub.status.busy":"2025-02-19T08:58:41.578741Z","iopub.execute_input":"2025-02-19T08:58:41.578936Z","iopub.status.idle":"2025-02-19T08:58:42.247885Z","shell.execute_reply.started":"2025-02-19T08:58:41.578919Z","shell.execute_reply":"2025-02-19T08:58:42.246822Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)\npeft_config = LoraConfig(\n    lora_alpha=32,\n    lora_dropout=0.1,\n    r=8,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"query\", \"value\"]\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T08:58:42.249844Z","iopub.execute_input":"2025-02-19T08:58:42.250123Z","iopub.status.idle":"2025-02-19T08:58:42.313378Z","shell.execute_reply.started":"2025-02-19T08:58:42.250101Z","shell.execute_reply":"2025-02-19T08:58:42.312560Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"tensorboard\",\n    hub_model_id=\"srinija2005/Test_1\"\n)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T08:58:42.314405Z","iopub.execute_input":"2025-02-19T08:58:42.314668Z","iopub.status.idle":"2025-02-19T08:58:42.340540Z","shell.execute_reply.started":"2025-02-19T08:58:42.314648Z","shell.execute_reply":"2025-02-19T08:58:42.339945Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = load_dataset(\"livinNector/indic_corp\")","metadata":{"execution":{"iopub.status.busy":"2025-02-19T08:58:42.341235Z","iopub.execute_input":"2025-02-19T08:58:42.341483Z","iopub.status.idle":"2025-02-19T09:03:20.528359Z","shell.execute_reply.started":"2025-02-19T08:58:42.341463Z","shell.execute_reply":"2025-02-19T09:03:20.527488Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\ntokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else \"[PAD]\"\ntokenizer.model_max_length = 512  # Ensure consistency with model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T08:28:08.196464Z","iopub.execute_input":"2025-02-19T08:28:08.196798Z","iopub.status.idle":"2025-02-19T08:28:08.201398Z","shell.execute_reply.started":"2025-02-19T08:28:08.196773Z","shell.execute_reply":"2025-02-19T08:28:08.200446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset\nsmall_dataset = dataset[\"train\"].shuffle(seed=42).select(range(int(0.005 * len(dataset[\"train\"]))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T08:28:11.200514Z","iopub.execute_input":"2025-02-19T08:28:11.200815Z","iopub.status.idle":"2025-02-19T08:28:24.005251Z","shell.execute_reply.started":"2025-02-19T08:28:11.200793Z","shell.execute_reply":"2025-02-19T08:28:24.004284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512  # Ensure it matches tokenizer.model_max_length\n    )\n\ntokenized_datasets = small_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T08:28:28.150312Z","iopub.execute_input":"2025-02-19T08:28:28.150641Z","iopub.status.idle":"2025-02-19T08:29:26.296572Z","shell.execute_reply.started":"2025-02-19T08:28:28.150618Z","shell.execute_reply":"2025-02-19T08:29:26.295662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=tokenized_datasets,  # Ensure tokenized dataset is used\n    peft_config=peft_config,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T08:29:34.384794Z","iopub.execute_input":"2025-02-19T08:29:34.385123Z","iopub.status.idle":"2025-02-19T08:31:29.794199Z","shell.execute_reply.started":"2025-02-19T08:29:34.385099Z","shell.execute_reply":"2025-02-19T08:31:29.793308Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T08:31:33.528888Z","iopub.execute_input":"2025-02-19T08:31:33.529296Z","iopub.status.idle":"2025-02-19T08:33:27.142464Z","shell.execute_reply.started":"2025-02-19T08:31:33.529260Z","shell.execute_reply":"2025-02-19T08:33:27.141164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# Define save path\nsave_directory = \"./fine_tuned_model\"\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\n\n# Save training arguments (if applicable)\ntraining_args.save_to_json(f\"{save_directory}/training_args.json\")\n\nprint(f\"Model saved to {save_directory}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T06:48:26.152377Z","iopub.execute_input":"2025-02-19T06:48:26.152762Z","iopub.status.idle":"2025-02-19T06:48:29.112025Z","shell.execute_reply.started":"2025-02-19T06:48:26.152733Z","shell.execute_reply":"2025-02-19T06:48:29.111299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n\n# Load your fine-tuned model\nmodel_name = \"srinija2005/MyModel\"  # Replace with your Hugging Face model ID or local path\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Ensure padding is correctly set\ntokenizer.pad_token = tokenizer.eos_token  \n\n# Create a text-generation pipeline\npipe = pipeline(\n    task=\"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    pad_token_id=tokenizer.eos_token_id,  \n    max_length=256,  # Adjust as needed\n    temperature=0.7,  # Adjust for randomness\n    top_p=0.95,  \n    repetition_penalty=1.15\n)\n\n# Define test prompts\ntest_prompts = [\n    \"‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§ï‡•å‡§® ‡§π‡•à?\",\n    \"AI ‡§ï‡§æ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\",\n    \"‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?\"\n]\n\n# Generate responses\nfor prompt in test_prompts:\n    print(f\"üìù **Prompt:** {prompt}\")\n    response = pipe(prompt, max_length=100, num_return_sequences=1)\n    print(f\"ü§ñ **Model Response:** {response[0]['generated_text']}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T07:08:45.607781Z","iopub.execute_input":"2025-02-19T07:08:45.608110Z","iopub.status.idle":"2025-02-19T07:08:59.624760Z","shell.execute_reply.started":"2025-02-19T07:08:45.608085Z","shell.execute_reply":"2025-02-19T07:08:59.623970Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipe = pipeline(\n    task=\"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    pad_token_id=tokenizer.eos_token_id,  # Ensure this is properly set\n    max_length=512,  # Change from 600 to 512 to match model's expected size\n    temperature=0,\n    top_p=0.95,\n    repetition_penalty=1.15\n)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T07:02:35.603873Z","iopub.execute_input":"2025-02-19T07:02:35.604302Z","iopub.status.idle":"2025-02-19T07:02:35.611761Z","shell.execute_reply.started":"2025-02-19T07:02:35.604253Z","shell.execute_reply":"2025-02-19T07:02:35.610840Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! pip install  langchain_community\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.document_loaders import DirectoryLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import HuggingFaceInstructEmbeddings\nfrom langchain.chains import RetrievalQA","metadata":{"execution":{"iopub.status.busy":"2025-02-19T07:02:40.204125Z","iopub.execute_input":"2025-02-19T07:02:40.204460Z","iopub.status.idle":"2025-02-19T07:02:40.209230Z","shell.execute_reply.started":"2025-02-19T07:02:40.204427Z","shell.execute_reply":"2025-02-19T07:02:40.208337Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline = pipe)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T07:02:43.265010Z","iopub.execute_input":"2025-02-19T07:02:43.265304Z","iopub.status.idle":"2025-02-19T07:02:43.269214Z","shell.execute_reply.started":"2025-02-19T07:02:43.265281Z","shell.execute_reply":"2025-02-19T07:02:43.268464Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.hf_device_map","metadata":{"execution":{"iopub.status.busy":"2025-02-19T07:02:45.446118Z","iopub.execute_input":"2025-02-19T07:02:45.446411Z","iopub.status.idle":"2025-02-19T07:02:45.451493Z","shell.execute_reply.started":"2025-02-19T07:02:45.446388Z","shell.execute_reply":"2025-02-19T07:02:45.450831Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"llm.invoke(\"‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç\")","metadata":{"execution":{"iopub.status.busy":"2025-02-19T07:03:52.108796Z","iopub.execute_input":"2025-02-19T07:03:52.109119Z","iopub.status.idle":"2025-02-19T07:04:15.039802Z","shell.execute_reply.started":"2025-02-19T07:03:52.109095Z","shell.execute_reply":"2025-02-19T07:04:15.039014Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loader = DirectoryLoader(\n    \"/kaggle/input/theripistbot\",\n    glob=\"./*.pdf\",\n    loader_cls=PyPDFLoader,\n    show_progress=True,\n    use_multithreading=True\n)\n\ndocuments = loader.load()","metadata":{"execution":{"iopub.status.busy":"2025-02-19T07:05:50.311864Z","iopub.execute_input":"2025-02-19T07:05:50.312218Z","iopub.status.idle":"2025-02-19T07:05:50.343653Z","shell.execute_reply.started":"2025-02-19T07:05:50.312187Z","shell.execute_reply":"2025-02-19T07:05:50.342445Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(documents)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"documents[72]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"st = \"\"\nfor i in documents:\n    st = st+i.dict()[\"page_content\"].replace(\"\\t\",\" \")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(st)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 800,\n    chunk_overlap = 0\n)\n\ntexts = text_splitter.split_text(st)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embeddings = HuggingFaceInstructEmbeddings(\n    model_name = \"sentence-transformers/all-MiniLM-L6-v2\",\n    model_kwargs = {\"device\": \"cuda\"}\n)\n\nvectordb = FAISS.from_texts(\n    texts = texts, \n    embedding = embeddings\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vectordb.similarity_search('depression')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_template = \"\"\"\nAsk for questions about how they feel about their problem.\nMake the user feel comfortable.\nAnswer in the same language the question was asked.\n\n{context}\n\nQuestion: {question}\nAnswer:\"\"\"\n\n\nPROMPT = PromptTemplate(\n    template = prompt_template, \n    input_variables = [\"context\", \"question\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"llm_chain = LLMChain(prompt=PROMPT, llm=llm)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"retriever = vectordb.as_retriever(search_kwargs = {\"k\": 3, \"search_type\" : \"similarity\"})\nqa_chain = RetrievalQA.from_chain_type(\n    llm = llm,\n    chain_type = \"stuff\",\n    retriever = retriever, \n    chain_type_kwargs = {\"prompt\": PROMPT},\n    return_source_documents = True,\n    verbose = True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def wrap_text_preserve_newlines(text, width=700):\n    lines = text.split('\\n')\n    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n    wrapped_text = '\\n'.join(wrapped_lines)\n    return wrapped_text\n\ndef process_llm_response(llm_response):\n    ans = wrap_text_preserve_newlines(llm_response['result'])\n\n    return ans","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nimport textwrap","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def llm_ans(query):\n    start = time.time()\n    \n    llm_response = qa_chain.invoke(query)\n    ans = process_llm_response(llm_response)\n    \n    end = time.time()\n\n    time_elapsed = int(round(end - start, 0))\n    time_elapsed_str = f'\\n\\nTime elapsed: {time_elapsed} s'\n    return ans + time_elapsed_str","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"llm_ans(\"i feel sad.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}